{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001fc986",
   "metadata": {},
   "source": [
    "# Processing The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9eee6c",
   "metadata": {},
   "source": [
    "This notebook is what was used to convert all of the .csv files to .feather files in order to make it easier and more efficient to work with the Data. \n",
    "\n",
    "<b>NOTE: This notebook was included in order to allow the Processed dataset to be re-obtainable if provided with the Original dataset. Running this notebook will likely take a decent amount of time, as it is re-writing hundreds of millions of rows of data.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9c53f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62796d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff906c4",
   "metadata": {},
   "source": [
    "## Loading DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a Dictionary to store the loaded datasets:\n",
    "DSets = {}\n",
    "\n",
    "# Grab the names of the .csv files to load:\n",
    "csvs = [name for name in os.listdir('./Data/Original') if name[-4:] == '.csv']\n",
    "\n",
    "## REMOVE UNNECESSARY CSVS HERE IF YOU DO NOT NEED TO REPROCESS SOME OF THEM\n",
    "csvs = csvs[3:]\n",
    "\n",
    "names = [name[:-4] for name in csvs]\n",
    "\n",
    "# Use dask to schedule loading the .csv files.\n",
    "for csv in csvs:\n",
    "    DSets[csv[:-4]] = dd.read_csv('./Data/Original/'+csv).compute()\n",
    "    print(csv, 'loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f254fb",
   "metadata": {},
   "source": [
    "### Count of Rows Loaded (For Curiosity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for csv in csvs:\n",
    "    counter += len(DSets[csv[:-4]])\n",
    "v = str(counter)\n",
    "print('Rows Loaded:', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6eb01",
   "metadata": {},
   "source": [
    "## Write DataFrames to Feather:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b072770",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    PATH = './Data/Processed/'+name+'.feather'\n",
    "    DSets[name].reset_index(drop=True).to_feather(PATH)\n",
    "    print('Finished writing', name+'.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef69fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
